# Models in R {#models}

## Packages required for this chapter

For this chapter you need to have the *tidyverse*, *broom* and *MuMIn* packages installed.

This chapter will explain how to generate models in R, how to obtain information and tables from models with the *Broom* package [@Robinson2018] and a brief introduction to model selection with the *MuMIn* package [@Barton2018 ]

This class of the course can also be followed at this [link](https://sustainscapes.github.io/Class3/Modelos.html). 

## Statistical models

A statistical model tries to explain the causes of an event based on a sample of the total population. The assumption is that if the sample we obtain from the population is representative of it, we will be able to infer the causes of the population variation by measuring explanatory variables. In general, we have a response variable (the phenomenon we want to explain), and one or more explanatory variables that would deterministically generate part of the variability in the response variable.

### Example

Let's take the example of the *CO2* database present in R [@potvin1990statistical]. Suppose we are interested in knowing what factors affect the uptake of $CO_2$ in plants.

```{r TablaCo2, echo = FALSE}
knitr::kable(CO2[1:20,], caption = 'First 20 observations of the CO2 database.', booktabs = TRUE, row.names = FALSE)
```

In the table \@ref(tab:TablaCo2) we see the first 20 observations of this database. We see that within the factors we have to explain the capture of $CO_2$ are:

* *Type:* Subspecies of plant (Mississippi or Quebec)
* *Treatment:* Plant treatment, chilled or nonchilled
* *conc:* Environmental concentration of $CO_2$, in mL/L.

A possible explanation that would allow us to try to explain this phenomenon is that the plants of different subspecies will have different uptake of $CO_2$, which we explore in the graph \@ref(fig:Subespecie):

```{r Subespecie, fig.cap='CO2 uptake by plants dependent on their subspecies', out.width='80%', fig.asp=.75, fig.align='center', echo = FALSE, cache = TRUE}

ggplot(CO2, aes(x = Type, y=uptake)) + geom_boxplot() + geom_jitter(aes(color = Type)) + theme_classic()
```

We see that there is a tendency for plants originating in Quebec to capture more $CO_2$ than those from the Mississippi, but can we effectively say that both populations have different means? That's where models come in.

### Representing a model in R

In R most models are represented with the following code:

```{r, echo = TRUE, eval=FALSE}
some_function(Y ~ X1 + X2 + ... + Xn, data = data.frame)
```

In this model, we have the response variable *Y*, which can be explained by one or multiple explanatory variables *X*, that is why the symbol `~` reads explained by, where what is on its left is the response variable and to the right the explanatory variable. The data is in a data frame and finally we will use some function, which will identify some model. Some of these functions are found in the table \@ref(tab:Modelos)

```{r Modelos, echo = FALSE}
Models <- data.frame(Modelos = c("t-test" ,"ANOVA", "Linear model", "Generalized linear model", "Generalized aditive model", "non-linear model", "Mixed effect models", "Boosted regression trees"), Funcion = c("t.test()", "aov()", "lm()", "glm()", "gam()", "nls()", "lmer()", "gbm()"))

knitr::kable(Models, caption = 'Some models that we can generate in R', booktabs = TRUE, row.names = FALSE)
```


### Let's go back to the example of plants

For this example we will use a simple linear model, for this following the table \@ref(tab:Modelos) lets use the `lm` function:

```{r}
Fit1 <- lm(uptake ~ Type, data = CO2)
```

#### Using broom to get more out of your model

the broom package [@Robinson2018] is a package adjacent to the tidyverse (so you have to load it separately from the tidyverse), which allows us to take information from models generated in tidy format. Today we will look at 3 *broom* functions, these are `glance`, `tidy` and `augment`.

##### glance

The glance function will give us general information about the model, such as the p value, the $R^2$, log-likelihood, degrees of freedom, and/or other parameters depending on the model to be used. This information is delivered to us in a data frame format, as we see in the following code and in the table \@ref(tab:glance)

```{r, eval=FALSE}
library(broom)
glance(Fit1)
```

```{r glance, echo = FALSE}
library(broom)
knitr::kable(glance(Fit1), caption = 'Model information fi1 delivered by the glance function', booktabs = TRUE, row.names = FALSE)
```

##### tidy

the tidy function will give us information about the model parameters, that is the intercept, the slope and/or interactions, as we see in the following code and in the table \@ref(tab:tidy)

```{r, eval=FALSE}
tidy(Fit1)
```

```{r tidy, echo = FALSE}
knitr::kable(tidy(Fit1), caption = 'Model information fit1 delivered by the glance function', booktabs = TRUE, row.names = FALSE)
```

##### augment

The augment function will give us, for each observation of our model, several important parameters such as the predicted value, the residuals, the cook distance, among others, this mainly serves us to study the assumptions of our model. Below we see the use of the `augment` function and 20 of its observations in the table \@ref(tab:augment)

```{r, eval=FALSE}
augment(Fit1)
```

```{r augment, echo = FALSE}
knitr::kable(sample_n(augment(Fit1), 20), caption = 'Fit1 model information returned by the augment function', booktabs = TRUE, row.names = FALSE)
```

#### Model selection using broom and the AIC

The AIC, or Akaike Information Criterion [@aho2014model], is a measure of how much information a model gives us given its complexity. This last measure from the number of parameters it has. The lower the AIC, the comparatively better a model is, and in general, a model that is two AIC units lower than another model will be considered a model that is significantly better than another.

The Akaike selection criterion formula is the one we see in the equation \@ref(eq:AIC).

\begin{equation} 
  AIC = 2 K - 2 \ln{(\hat{L})}
  (\#eq:AIC)
\end{equation} 


Where $K$ is the number of parameters, which we can see with tidy, if we look at the table \@ref(tab:tidy), we see that the model *Fit1* has 2 parameters, that is $K$ is equal to 2 .

The log-likelihood of the model ($\ln{(\hat{L})}$) is the fit it has to the data. The more positive this value is, the better the model fits the data, and the more negative it is, the less it fits the data. In our model, using glance, we can see that the model's log-likelyhood value is -300.8 (see table \@ref(tab:tidy)).

Therefore, substituting the equation \@ref(eq:AIC), we obtain 605.6, which is a value very close to the 608, which appear in the model's glance (table \@ref(tab:tidy)).

##### Candidate Models

Let's look at the figure \@ref(fig:CO2Mods). to think about what might be interesting models to explore.

```{r CO2Mods, fig.cap='Exploratory graph to generate models from the CO2 database', out.width='80%', fig.asp=.75, fig.align='center', echo = TRUE, cache = TRUE}
ggplot(CO2, aes(x = conc, y = uptake)) + geom_point(aes(color = Type, shape = Treatment), size = 3)
```
