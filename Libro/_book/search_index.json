[["index.html", "Reproducible research in R Requirements 0.1 Before starting 0.2 Workshop description 0.3 Course Objectives 0.4 Contents 0.5 Libros de consulta 0.6 Reference books 0.7 References", " Reproducible research in R Derek Corcoran 2022-03-16 Requirements To start the job you need the latest version of R and RStudio (R Core Team 2021). The rmarkdown, tidyverse and tinytex packages are also required. The code for installing those packages is as follows: install.packages(&quot;rmarkdown&quot;, &quot;tidyverse&quot;, &quot;tinytex&quot;) 0.1 Before starting If you have never worked with R before this course, a good tool is provided by the Swirl (Kross et al. 2017) package. To begin with, complete the first 7 modules of the program R Programming: The basics of programming in R which includes: Basic Building Blocks Workspace and Files Sequences of Numbers Vectors Missing Values Subsetting Vectors Arrays and Data Frames 0.2 Workshop description This course is focused on delivering basic principles of reproducible research in R, with an emphasis on collecting and/or reading data in a reproducible and automated way. For this, we will work with complex databases, which must be transformed and organized to optimize their analysis. Reproducible documents will be generated by integrating in one document: code, bibliography, exploration and data analysis. The course will culminate with the generation of a reproducible manuscript, presentation and/or interactive document. and the necessary metadata 0.3 Course Objectives Know and understand the concept of Reproducible Research as a form and philosophy of research that allows investigations to be more orderly and replicable, from data collection to writing results. Know and apply the concept of pipeline, which allows generating modularity from data collection to writing results, where the independent correction of a step has a cascading effect on the final result. Learn good database collection and standardization practices, in order to optimize data analysis and peer review. Perform critical analyzes of the nature of the data when conducting exploratory analyzes, which will allow determining the best way to test hypotheses associated with these databases. Generating Metadata for your studies to ensure other researchers understand what your data means 0.4 Contents Chapter 1 Tidy Data: In this chapter you will learn how to optimize a database, about cleaning and transforming databases, what a tidy database is and how to manipulate these databases with the dplyr package (Wickham et al. 2022). Chapter 2 Reproducible research: In this chapter we will work on making a document that combines R codes and text to generate reproducible documents using the rmarkdown (Allaire et al. 2018) package. In addition, you will see how using RStudio you can save projects to a github repository. Chapter 4 Models in R Learn how to generate models in R, from ANOVA to GLM. Chapter ?? The tidyverse and the pipeline concept: In this chapter you will learn about cleaning complex data. Chapter ?? Data visualization visualize data vs. view models. Insert graphics with legend in an Rmd document Chapter ?? Loops. Generation of own functions in R and loops Writing scripts in R, transforming Rmd documents into a script Presentations in R and generate interactive documents. Transformation of data in a presentation or in a Shiny app. Make a presentation or application in R. 0.5 Libros de consulta Los principios de este curso están explicados en los siguientes libros gratuitos. Gandrud, Christopher. Reproducible Research with R and R Studio. CRC Press, 2013. Available for free in the following link Stodden, Victoria, Friedrich Leisch, and Roger D. Peng, eds. Implementing reproducible research. CRC Press, 2014. Available for free in the following link 0.6 Reference books The principles of this course are explained in the following free books. Gandrud, Christopher. Reproducible Research with R and R Studio. CRC Press, 2013. Available for free in the following link Stodden, Victoria, Friedrich Leisch, and Roger D. Peng, eds. Implementing reproducible research. CRC Press, 2014. Available for free in the following link 0.7 References References "],["tidydata.html", "Chapter 1 Tidy Data and data manipulation 1.1 Packages needed for this chapter 1.2 Tidy data 1.3 dplyr", " Chapter 1 Tidy Data and data manipulation 1.1 Packages needed for this chapter For this chapter you need to have the tidyverse package installed. This chapter will explain what a tidy (Wickham and others 2014) database is and learn how to use functions from the dplyr (Wickham et al. 2022) package to manipulate data. This class of the course can also be followed at this link. 1.2 Tidy data A tidy database is a database in which (modified from (Leek 2015)): Each variable to be measured must be in a column. Each observation other than that variable must be in a different row. In general, the way we would represent a tidy database in R is by using a data frame. 1.3 dplyr The dplyr package is defined by its authors as a grammar for data manipulation. Thus their functions are known as verbs. A helpful summary of many of these features is found at this link. This package has a large number of verbs and it would be difficult to see all of them in one class, in this chapter we will focus on its most used functions, which are: %&gt;% (pipelines) group_by (group data) summarize (summarize grouped data) mutate (generate new variables) filter (find rows with certain conditions) select next to starts_with, ends_with or contains in the next section you can learn about the pipeline (%&gt;%), group_by and summarize 1.3.1 Pipeline (%&gt;%) The pipeline is an operator symbol %&gt;% that is used to perform various operations sequentially without resorting to nested parentheses or overwriting multiple databases. To see how this works as a vector, suppose you have a variable that you want to first get its logarithm, then its square root, and finally its average to two significant figures. To do this, the following must be followed: x &lt;- c(1, 4, 6, 8) y &lt;- round(mean(sqrt(log(x))), 2) If pipelined, the code would be much neater. In that case, it would start with the object to be processed and then each of the functions with their arguments if necessary: x &lt;- c(1, 4, 6, 8) y &lt;- x %&gt;% log() %&gt;% sqrt() %&gt;% mean() %&gt;% round(2) ## [1] 0.99 Piped code is much easier to interpret at first glance since it reads from left to right and not from the inside out. 1.3.2 summarize The summarize function takes the data from a data frame and summarizes it. To use this function, the first argument we would take would be a data frame, followed by the name we want to give to a summary variable, followed by the = sign and then the formula to apply to one or more columns. As an example we will use the iris database (Anderson 1935) that comes in R and of which we can see part of its data in the table 1.1 Table 1.1: a table with 10 rows from the iris database. Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.8 4.0 1.2 0.2 setosa 4.7 3.2 1.6 0.2 setosa 5.1 3.8 1.9 0.4 setosa 5.2 2.7 3.9 1.4 versicolor 6.4 2.9 4.3 1.3 versicolor 5.5 2.5 4.0 1.3 versicolor 6.5 3.0 5.8 2.2 virginica 6.0 2.2 5.0 1.5 virginica 6.1 2.6 5.6 1.4 virginica 5.9 3.0 5.1 1.8 virginica If we wanted to summarize that table and generate a couple of variables that were the mean and standard deviation of the length of the petal, we would do it with the following code: library(tidyverse) Summary.Petal &lt;- summarize(iris, Mean.Petal.Length = mean(Petal.Length), SD.Petal.Length = sd(Petal.Length)) The result can be seen in the table 1.2, in which the averages and standard deviations of the lengths of the petals are obtained. It is important to note that when using summarize, all other variables will disappear from the table. Table 1.2: Summary of the mean and standard deviation of the petal length of the flowers of the genus Iris. Mean.Petal.Length SD.Petal.Length 3.758 1.765298 1.3.3 group_by The group_by function itself does not cause any visible changes to the databases. However, when used in conjunction with summarize it allows you to summarize a grouped variable (usually) based on one or more categorical variables. It can be seen that for the example with the case of plants of the genus Iris, the summary obtained in the case of the table 1.2 is not so useful considering that we have three species present. If you want to see the average length of the petal by species, you must use the group_by function as follows: BySpecies &lt;- group_by(iris, Species) Summary.Byspecies &lt;- summarize(BySpecies, Mean.Petal.Length = mean(Petal.Length), SD.Petal.Length = sd(Petal.Length)) This results in the table 1.3, from which you can see that Iris setosa has much shorter petals than the other two species of the same genus. Table 1.3: Summary of the mean and standard deviation of the petal length of the flowers of the genus Iris. Species Mean.Petal.Length SD.Petal.Length setosa 1.462 0.1736640 versicolor 4.260 0.4699110 virginica 5.552 0.5518947 1.3.3.1 group_by on more than one variable You can use the group_by function on more than one variable, and this would result in a nested summary. As an example we will use the mtcars database present in R (Henderson and Velleman 1981). This database features a variable called mpg (miles per gallon) and a measure of fuel efficiency. The information will be summarized based on the variable am (which refers to the type of transmission, where 0 is automatic and 1 is manual) and the number of engine cylinders. For that, the following code will be used: Grouped &lt;- group_by(mtcars, cyl, am) Efficiency &lt;- summarize(Grouped, Efficiency = mean(mpg)) As can be seen in the table 1.4, in all cases cars with manual transmissions have better fuel efficiency. You could try changing the order of the variables with which to group and observe the different results that can be obtained. Table 1.4: Average miles per gallon in automatic (am = 0) and manual (am = 1) vehicles, with the different types of cylinders cyl am Efficiency 4 0 22.90000 4 1 28.07500 6 0 19.12500 6 1 20.56667 8 0 15.05000 8 1 15.40000 1.3.4 mutate This function aims to create new variables based on other variables. It is very easy to use, as an argument the name of the new variable that you want to create is used and an operation is performed with variables that are already there. For example, if we continue working with the Iris database, by creating a new variable that is the ratio between the length of the petal and the length of the sepal, the following results: DF &lt;- mutate(iris, Petal.Sepal.Ratio = Petal.Length/Sepal.Length) The result of this operation is the table 1.5. The variable that has just been created will always appear at the end of the data frame. Table 1.5: Table with ten of the observations from the new database with the new variable created with mutate Sepal.Length Sepal.Width Petal.Length Petal.Width Species Petal.Sepal.Ratio 5.8 4.0 1.2 0.2 setosa 0.21 4.7 3.2 1.6 0.2 setosa 0.34 5.1 3.8 1.9 0.4 setosa 0.37 5.2 2.7 3.9 1.4 versicolor 0.75 6.4 2.9 4.3 1.3 versicolor 0.67 5.5 2.5 4.0 1.3 versicolor 0.73 6.5 3.0 5.8 2.2 virginica 0.89 6.0 2.2 5.0 1.5 virginica 0.83 6.1 2.6 5.6 1.4 virginica 0.92 5.9 3.0 5.1 1.8 virginica 0.86 1.3.4.1 The pipeline in data frames For example, we want to summarize the newly created variable of the ratio between the sepal and the petal. To do this, if starting from the original database, it would take several lines of code and the creation of multiple intermediate databases. DF &lt;- mutate(iris, Petal.Sepal.Ratio = Petal.Length/Sepal.Length) BySpecies &lt;- group_by(DF, Species) Summary.Byspecies &lt;- summarize(BySpecies, MEAN = mean(Petal.Sepal.Ratio), SD = sd(Petal.Sepal.Ratio)) Another option is to use nested parentheses, which results in the following code: Summary.Byspecies &lt;- summarize(group_by(mutate(iris, Petal.Sepal.Ratio = Petal.Length/Sepal.Length), Species), MEAN = mean(Petal.Sepal.Ratio), SD = sd(Petal.Sepal. Ratio)) This is further simplified by using the pipeline, which allows you to start at a Data Frame and then use the pipeline. This allows to obtain the same result as in the previous operations with the following code: Summary.Byspecies &lt;- iris %&gt;% mutate(Petal.Sepal.Ratio = Petal.Length/Sepal.Length) %&gt;% group_by(Species) %&gt;% summarize(MEAN = mean(Petal.Sepal.Ratio), SD = sd(Petal.Sepal.Ratio)) These three codes are correct (table 1.6), but definitely the use of the pipeline gives the most concise and easy to interpret code without intermediate steps. Table 1.6: Average petal-sepal ratio for the three Iris species Species MEAN SD setosa 0.2927557 0.0347958 versicolor 0.7177285 0.0536255 virginica 0.8437495 0.0438064 1.3.5 filter This function allows you to select rows that meet certain conditions, such as having a value greater than a threshold or belonging to a certain class. The most typical symbols to use in this case are those seen in the table 1.7. Table 1.7: R logical symbols and their meaning symbol meaning cont_symbol cont_meaning &gt; Greater than != other than &lt; Less than %in% within group == Equal to is.na is NA &gt;= greater than or equal to !is.na is not NA &lt;= less than or equal to | &amp; or, and For example, if you want to study the floral characteristics of plants of the genus Iris, but do not take into account the species Iris versicolor, you should use the following code: data(&quot;iris&quot;) DF &lt;- iris %&gt;% filter(Species != &quot;versicolor&quot;) %&gt;% group_by(Species) %&gt;% summarise_all(mean) This results in the table 1.8. In this case, the summarize_all function of summarize is introduced, which applies the function given as an argument to all variables in the database. Table 1.8: Summary of the mean of all floral characteristics of the species Iris setosa and Iris virginica Species Sepal.Length Sepal.Width Petal.Length Petal.Width setosa 5.006 3.428 1.462 0.246 virginica 6.588 2.974 5.552 2.026 On the other hand, if you want to study how many plants of each species have a petal length greater than 4 and a sepal length greater than 5, you should use the following code: DF &lt;- iris %&gt;% filter(Petal.Length &gt;= 4 &amp; Sepal.Length &gt;= 5) %&gt;% group_by(Species) %&gt;% summarise(N = n()) In the table table 1.9 it can be seen that with this filter all Iris setosa plants disappear from the database and that all except one Iris virginica plant have both characteristics. Table 1.9: Number of plants of each species with a petal length greater than 4 and a sepal length greater than 5 centimeters Species N versicolor 39 virginica 49 1.3.6 select This function allows you to select the variables to use since in many cases we will find databases with too many variables and therefore, we will want to reduce them to only work on a table with the necessary variables. With select there are several ways to work, on the one hand you can write the variables that will be used, or subtract those that will not. In that sense these four codes give exactly the same result. This can be seen in the table 1.10 iris %&gt;% group_by(Species) %&gt;% select(Petal.Length, Petal.Width) %&gt;% summarize_all(mean) iris %&gt;% group_by(Species) %&gt;% select(-Sepal.Length, -Sepal.Width) %&gt;% summarize_all(mean) iris %&gt;% group_by(Species) %&gt;% select(contains(&quot;Petal&quot;)) %&gt;% summarize_all(mean) iris %&gt;% group_by(Species) %&gt;% select(-contains(&quot;Sepal&quot;)) %&gt;% summarize_all(mean) Table 1.10: Average petal length and petal width for species of the genus Iris Species Petal.Length Petal.Width setosa 1.462 0.246 versicolor 4.260 1.326 virginica 5.552 2.026 1.3.7 Exercises 1.3.7.1 Exercise 1 Using the storms database from the dplyr package, compute the average speed and average diameter (hu_diameter) of storms that have been declared hurricanes for each year. 1.3.7.2 Exercise 2 The ggplot2 package’s mpg database has fuel economy data in city miles per gallon (cty) for various vehicles. Obtain the data of vehicles from the year 2004 onwards that are compact and transform the efficiency Km/liter (1 mile = 1,609 km; 1 gallon = 3.78541 liters) References "],["reproducible.html", "Chapter 2 Reproducible research 2.1 Packages needed for this chapter 2.2 Reproducible Research 2.3 Saving our project on github 2.4 Reproducibility in R subtitle 1", " Chapter 2 Reproducible research 2.1 Packages needed for this chapter For this chapter you need to have the rmarkdown, knitr, reprex and kableExtra packages installed. This chapter will explain what reproducible research is, how to apply it using github plus the rmarkdown (Allaire et al. 2018) and knitr (Xie 2015) packages. Also, you will learn how to use tables using knitr (Xie 2015) and kableExtra (Zhu 2021). In order to use GitHub you need a GitPat, in order to get that, an easy option to generate it through the usethis package (Wickham, Bryan, and Barrett 2021). Finally you will learn how use reprex in order to generate reproducible questions in stackoverflow. This class of the course can also be followed at this link. 2.2 Reproducible Research Reproducible research is not the same as replicable research. Replicability implies that experiments or studies carried out under similar conditions will lead to similar conclusions. Reproducible research implies that from the same data and/or the same code the same results will be generated. Figure 2.1: Continuum of reproducibility (extracted from Peng 2011) In the figure 2.1 we see the reproducibility continuum (Peng 2011). In this continuum we have the example of non-reproducibility as a post without code. It goes from less reproducible to more reproducible by the publication and the code that generated the results and graphs; followed by the publication, the code and the data that generate the results and graphs; and finally code, data and text intertwined in such a way that when running the code we get exactly the same publication that we read. This has many advantages, including making it easier to apply the exact same methods to another database. It is enough to put the new database in the format that the author of the first publication had and we can compare the results. Also, at a time when science is increasingly database-based, data collection and/or sampling can be put into code. 2.3 Saving our project on github 2.3.1 What is github? Github is a kind of dropbox or google drive designed for reproducible research, where each project is a repository. Most researchers working on reproducible research leave all of their documented work in their repositories, allowing you to interact with other authors. 2.3.2 creating a github project in RStudio To create a project on github we press start a project on the home page of our account, as we see in the figure 2.2 Figure 2.2: To start a project on github, you must press Start a project on your home page Then a unique name must be created, and without changing anything else press create repository on the green button as we see in the figure 2.3. Figure 2.3: Create the name of your repository and press the button create repository This will take you to a page where a url of your new repository will appear as in the figure 2.4 Figure 2.4: The content of the box that says ssh is the url of your repository To incorporate your project into your repository, the first thing you need to do is generate a project in RStudio. For this you must go in the top menu of Rstudio to File &gt; New Project &gt; Git as seen in the figures 2.5 and 2.5. Figure 2.5: Menu to create a new project Figure 2.6: Select git within the options Then select the location of the new project and paste the url that appears in the figure 2.4 in the space that says Repository URL:, as shown in the figure 2.7 . Figure 2.7: Paste the repository url into the Repository URL: dialog When your R project is already following the changes on github, a git tab will appear in the upper right window of your RStudio session, as we see in the figure 2.8 Figure 2.8: Al incluir tu repositorio en tu sesión de Rstudio, aparecera la pestaña git en la ventana superior derecha 2.3.3 The three main steps of a repository Github is a whole world, there are many functions and there are experts in the use of github. In this course, we will focus on the 3 main steps of a repository: add, commit and push. To fully understand what each of these steps means, we have to understand that there are two repositories at all times: a local one (on your computer) and a remote one (on github.com). The first two steps add and commit only output changes to your local repository. While push saves the changes to the remote repository. 2.3.3.1 git add This function is what adds files to your local repository. Only these files will be saved on github. Github have a repository size limit of 1 GB and files of 100 MB, since although they give you unlimited repositories, the space of each one is not, particularly in terms of databases. To add a file to your repository you just have to select the files in the git tab. By doing that a green letter A will appear instead of the two yellow question marks, as we see in the figure 2.9. In this case we only add the file Analisis.r to the repository but not the rest. Figure 2.9: When including your repository in your Rstudio session, the git tab will appear in the upper right window 2.3.3.2 git commit When you use the commit command you are saving the changes to the files you added to your local repository. To do this in Rstudio, in the same git tab, you must press the commit button as we see in the figure 2.10. Figure 2.10: To save changes to your repository, press commit in the git tab in the upper right window Pressing commit will open a pop-up window, where you will need to write a message describing what you will save. Once I’ve done that, press commit again in the popup as shown in figure 2.11. Figure 2.11: Write a message that remembers the changes you made to the popup 2.3.3.3 git push Finally, push will allow you to save changes to your remote repository, which secures your data in the cloud and also makes it available to other researchers. After pressing commit on the popup window (figure 2.11), we can press push on the green arrow on the popup window as seen in figure 2.12. Then we will be asked for our username and password, and we can check that our repository is online by entering our github session. Figure 2.12: To save to the remote repository press push on the popup window 2.4 Reproducibility in R There are several packages that allow us to do reproducible research in R, but without a doubt the most relevant are rmarkdown and knitr. Both packages work together when we generate an Rmd (Rmarkdown) file, in which we use text, R code and other elements at the same time to generate a word document, pdf, web page, presentation and/or web application (fig. 2.13). Figure 2.13: The goal of Rmarkdown is to merge r code with text and data to generate a reproducible document 2.4.1 Creating an Rmarkdown To create an Rmarkdown file, simply go to the menu File &gt; New file &gt; Rmarkdown and with that you will have created a new Rmd file. We will see some of the most typical elements of an Rmarkdown file. 2.4.1.1 Markdown The markdown is the part of the file where we simply write text, although it has some formatting details such as generating bold text, italics, titles and subtitles. To make text bold, it must be between two **bold** asterisks, for text to appear italic it must be between *italic* asterisks. Other examples are the titles of different levels, which are denoted with different numbers of #, as well as the following 4 titles or subtitles: subtitle 1 subtitle 2 subtitle 3 subtitle 4 it would look like this in code ## subtitle 1 ### subtitle 2 #### subtitle 3 ##### subtitle 4 2.4.1.2 Chunks Chunks are one of the most important parts of an Rmarkdown. These are where the code from R (or other programming languages) is added. Which allows the product of our code not to be just a script with pasted results, but actually generated in the same document as our script. The easiest way to add a chunk is by pressing the insert chunk button in Rstudio, this button is located in the upper left window of our RStudio session, as shown in the figure 2.14 Figure 2.14: When pressing the insert chunk button, a space will appear in which to insert code By pressing this button a space will appear, there you can add a code like the one below, and see the results below. ```{r} library(tidyverse) iris %&gt;% group_by(Species) %&gt;% summarize(Petal.Length = mean(Petal.length)) ``` ## # A tibble: 3 × 2 ## Species Petal.Length ## &lt;fct&gt; &lt;dbl&gt; ## 1 setosa 1.46 ## 2 versicolor 4.26 ## 3 virginica 5.55 2.4.1.2.1 Chunk Options There are many options for chunks, a complete documentation can be found at the following link, but here we will show the most common: echo = T or F show or not the code, respectively message = T or F displays packet messages, respectively warning = T or F displays warnings, respectively eval = T or F to evaluate or not the code, respectively cache = T or F save or not the result, respectively 2.4.1.3 inline code The inline codes are useful to add some value in the text, such as the value of p or the mean. To use it, put a backtick (backsingle quote), r, the code in question and another backtick as follows `r R_code`. We cannot put anything in an inline code, since it can only generate vectors, which often requires a lot of creativity to achieve what we want. For example if we wanted to put the average sepal length of the iris database into an inline code we would put `r mean(iris$Sepal.Length)`, which would result in 5.8433333. As a number with 7 significant figures would look strange in a text, we would also like to use the round function, so that it has 2 significant figures, for that we put the following inline code `r round(mean( iris$Sepal.Length),2)` which returns 5.84. This can be made even more complex if you want to work with a summary table. For example, if we wanted to list the average sepal size we would use summarize from dplyr, but this would result in a data.frame, which doesn’t appear if we try to inline code. Let’s start by seeing how the code would look where we obtained the average size of the sepal. iris %&gt;% group_by(Species) %&gt;% summarize(Mean = mean(Sepal.Length)) We would see the result of that code 2.1 Table 2.1: Summary of the average length of the sepal of the flowers of the genus Iris. Species Mean setosa 5.006 versicolor 5.936 virginica 6.588 To remove the mean vector from this data frame we could subset it with the $ sign. So if we want to output the Mean column of the data frame we created as a vector, we would do the following `r (iris %&gt;% group_by(Species) %&gt;% summarize(Mean = mean(Sepal.Length )))$Mean`. This would output 5.006, 5.936, 6.588. 2.4.2 Training 2.4.2.1 Exercise 1 Using the iris database, create an inline code that tells the average length of the petal of the species Iris virginica 2.4.2.2 Tables in Rmarkdown The most typical function for generating tables in an rmd file is kable from the knitr package, which in its simplest form includes a dataframe as its only argument. In addition to this, we can add some parameters such as caption, which allows us to put a title to the table or row.names, which if put as seen in the code (FALSE) will not show the names of the rows, as seen in the table 2.2. DF &lt;- iris %&gt;% group_by(Species) %&gt;% summarize_all(mean) kable(DF, caption = &quot;Average per species of all iris database variables.&quot;, row.names = FALSE) Table 2.2: Average per species of all iris database variables. Species Sepal.Length Sepal.Width Petal.Length Petal.Width setosa 5.006 3.428 1.462 0.246 versicolor 5.936 2.770 4.260 1.326 virginica 6.588 2.974 5.552 2.026 References "],["references-1.html", "Chapter 3 References", " Chapter 3 References "],["models.html", "Chapter 4 Models in R 4.1 Packages required for this chapter 4.2 Statistical models", " Chapter 4 Models in R 4.1 Packages required for this chapter For this chapter you need to have the tidyverse, broom and MuMIn packages installed. This chapter will explain how to generate models in R, how to obtain information and tables from models with the Broom package (Robinson and Hayes 2018) and a brief introduction to model selection with the MuMIn package (Barton 2018 ) This class of the course can also be followed at this link. 4.2 Statistical models A statistical model tries to explain the causes of an event based on a sample of the total population. The assumption is that if the sample we obtain from the population is representative of it, we will be able to infer the causes of the population variation by measuring explanatory variables. In general, we have a response variable (the phenomenon we want to explain), and one or more explanatory variables that would deterministically generate part of the variability in the response variable. 4.2.1 Example Let’s take the example of the CO2 database present in R (Potvin, Lechowicz, and Tardif 1990). Suppose we are interested in knowing what factors affect the uptake of \\(CO_2\\) in plants. Table 4.1: First 20 observations of the CO2 database. Plant Type Treatment conc uptake Qn1 Quebec nonchilled 95 16.0 Qn1 Quebec nonchilled 175 30.4 Qn1 Quebec nonchilled 250 34.8 Qn1 Quebec nonchilled 350 37.2 Qn1 Quebec nonchilled 500 35.3 Qn1 Quebec nonchilled 675 39.2 Qn1 Quebec nonchilled 1000 39.7 Qn2 Quebec nonchilled 95 13.6 Qn2 Quebec nonchilled 175 27.3 Qn2 Quebec nonchilled 250 37.1 Qn2 Quebec nonchilled 350 41.8 Qn2 Quebec nonchilled 500 40.6 Qn2 Quebec nonchilled 675 41.4 Qn2 Quebec nonchilled 1000 44.3 Qn3 Quebec nonchilled 95 16.2 Qn3 Quebec nonchilled 175 32.4 Qn3 Quebec nonchilled 250 40.3 Qn3 Quebec nonchilled 350 42.1 Qn3 Quebec nonchilled 500 42.9 Qn3 Quebec nonchilled 675 43.9 In the table 4.1 we see the first 20 observations of this database. We see that within the factors we have to explain the capture of \\(CO_2\\) are: Type: Subspecies of plant (Mississippi or Quebec) Treatment: Plant treatment, chilled or nonchilled conc: Environmental concentration of \\(CO_2\\), in mL/L. A possible explanation that would allow us to try to explain this phenomenon is that the plants of different subspecies will have different uptake of \\(CO_2\\), which we explore in the graph 4.1: Figure 4.1: CO2 uptake by plants dependent on their subspecies We see that there is a tendency for plants originating in Quebec to capture more \\(CO_2\\) than those from the Mississippi, but can we effectively say that both populations have different means? That’s where models come in. 4.2.2 Representing a model in R In R most models are represented with the following code: some_function(Y ~ X1 + X2 + ... + Xn, data = data.frame) In this model, we have the response variable Y, which can be explained by one or multiple explanatory variables X, that is why the symbol ~ reads explained by, where what is on its left is the response variable and to the right the explanatory variable. The data is in a data frame and finally we will use some function, which will identify some model. Some of these functions are found in the table 4.2 Table 4.2: Some models that we can generate in R Modelos Funcion t-test t.test() ANOVA aov() Linear model lm() Generalized linear model glm() Generalized aditive model gam() non-linear model nls() Mixed effect models lmer() Boosted regression trees gbm() 4.2.3 Let’s go back to the example of plants For this example we will use a simple linear model, for this following the table 4.2 lets use the lm function: Fit1 &lt;- lm(uptake ~ Type, data = CO2) 4.2.3.1 Using broom to get more out of your model the broom package (Robinson and Hayes 2018) is a package adjacent to the tidyverse (so you have to load it separately from the tidyverse), which allows us to take information from models generated in tidy format. Today we will look at 3 broom functions, these are glance, tidy and augment. 4.2.3.1.1 glance The glance function will give us general information about the model, such as the p value, the \\(R^2\\), log-likelihood, degrees of freedom, and/or other parameters depending on the model to be used. This information is delivered to us in a data frame format, as we see in the following code and in the table 4.3 library(broom) glance(Fit1) Table 4.3: Model information fi1 delivered by the glance function r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC deviance df.residual nobs 0.346713 0.3387461 8.794012 43.5191 0 1 -300.8007 607.6014 614.8939 6341.441 82 84 4.2.3.1.2 tidy the tidy function will give us information about the model parameters, that is the intercept, the slope and/or interactions, as we see in the following code and in the table 4.4 tidy(Fit1) Table 4.4: Model information fit1 delivered by the glance function term estimate std.error statistic p.value (Intercept) 33.54286 1.356945 24.719384 0 TypeMississippi -12.65952 1.919011 -6.596901 0 4.2.3.1.3 augment The augment function will give us, for each observation of our model, several important parameters such as the predicted value, the residuals, the cook distance, among others, this mainly serves us to study the assumptions of our model. Below we see the use of the augment function and 20 of its observations in the table 4.5 augment(Fit1) Table 4.5: Fit1 model information returned by the augment function uptake Type .fitted .resid .hat .sigma .cooksd .std.resid 28.5 Mississippi 20.88333 7.6166667 0.0238095 8.806572 0.0093715 0.8766185 15.1 Quebec 33.54286 -18.4428571 0.0238095 8.601612 0.0549457 -2.1226279 41.4 Quebec 33.54286 7.8571429 0.0238095 8.803900 0.0099726 0.9042954 19.4 Mississippi 20.88333 -1.4833333 0.0238095 8.846557 0.0003554 -0.1707200 37.2 Quebec 33.54286 3.6571429 0.0238095 8.838566 0.0021605 0.4209084 11.3 Mississippi 20.88333 -9.5833333 0.0238095 8.782250 0.0148358 -1.1029663 34.8 Quebec 33.54286 1.2571429 0.0238095 8.847000 0.0002553 0.1446873 27.8 Mississippi 20.88333 6.9166667 0.0238095 8.813874 0.0077281 0.7960540 7.7 Mississippi 20.88333 -13.1833333 0.0238095 8.723037 0.0280755 -1.5172980 38.7 Quebec 33.54286 5.1571429 0.0238095 8.829102 0.0042963 0.5935466 41.8 Quebec 33.54286 8.2571429 0.0238095 8.799269 0.0110138 0.9503322 30.4 Quebec 33.54286 -3.1428571 0.0238095 8.841068 0.0015956 -0.3617181 30.9 Mississippi 20.88333 10.0166667 0.0238095 8.776132 0.0162078 1.1528396 30.0 Mississippi 20.88333 9.1166667 0.0238095 8.788531 0.0134261 1.0492567 34.6 Quebec 33.54286 1.0571429 0.0238095 8.847331 0.0001805 0.1216688 19.9 Mississippi 20.88333 -0.9833333 0.0238095 8.847439 0.0001562 -0.1131739 42.9 Quebec 33.54286 9.3571429 0.0238095 8.785334 0.0141437 1.0769336 32.4 Mississippi 20.88333 11.5166667 0.0238095 8.752828 0.0214255 1.3254778 35.0 Quebec 33.54286 1.4571429 0.0238095 8.846612 0.0003430 0.1677057 18.1 Mississippi 20.88333 -2.7833333 0.0238095 8.842591 0.0012514 -0.3203398 4.2.3.2 Model selection using broom and the AIC The AIC, or Akaike Information Criterion (Aho, Derryberry, and Peterson 2014), is a measure of how much information a model gives us given its complexity. This last measure from the number of parameters it has. The lower the AIC, the comparatively better a model is, and in general, a model that is two AIC units lower than another model will be considered a model that is significantly better than another. The Akaike selection criterion formula is the one we see in the equation (4.1). \\[\\begin{equation} AIC = 2 K - 2 \\ln{(\\hat{L})} \\tag{4.1} \\end{equation}\\] Where \\(K\\) is the number of parameters, which we can see with tidy, if we look at the table 4.4, we see that the model Fit1 has 2 parameters, that is \\(K\\) is equal to 2 . The log-likelihood of the model (\\(\\ln{(\\hat{L})}\\)) is the fit it has to the data. The more positive this value is, the better the model fits the data, and the more negative it is, the less it fits the data. In our model, using glance, we can see that the model’s log-likelyhood value is -300.8 (see table 4.4). Therefore, substituting the equation (4.1), we obtain 605.6, which is a value very close to the 608, which appear in the model’s glance (table 4.4). 4.2.3.2.1 Candidate Models Let’s look at the figure 4.2. to think about what might be interesting models to explore. ggplot(CO2, aes(x = conc, y = uptake)) + geom_point(aes(color = Type, shape = Treatment), size = 3) Figure 4.2: Exploratory graph to generate models from the CO2 database "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
